import sys
import os
from dataclasses import dataclass

# --------------------------
# æ•°æ®ç±»ï¼šå­˜å‚¨è¯­æ³•ç»“æ„å…³é”®ä¿¡æ¯ï¼ˆä¾›ä¸­é—´ä»£ç ç”Ÿæˆå‚è€ƒï¼‰
# --------------------------
@dataclass
class SyntaxStructure:
    """è¯­æ³•ç»“æ„æ‘˜è¦ï¼Œé¢å‘ä¸­é—´ä»£ç ç”Ÿæˆäººå‘˜"""
    type: str          # ç»“æ„ç±»å‹ï¼ˆå‡½æ•°å®šä¹‰/å˜é‡å£°æ˜/èµ‹å€¼è¯­å¥ç­‰ï¼‰
    name: str          # åç§°ï¼ˆå‡½æ•°å/å˜é‡åï¼‰
    scope: str         # ä½œç”¨åŸŸï¼ˆå…¨å±€/å‡½æ•°å†…ï¼‰
    line: int          # æ‰€åœ¨è¡Œå·
    attrs: dict        # é™„åŠ å±æ€§ï¼ˆå¦‚å‚æ•°åˆ—è¡¨ã€è¿”å›å€¼ç±»å‹ã€è¡¨è¾¾å¼ç­‰ï¼‰

# --------------------------
# è·¯å¾„é…ç½®ä¸æ¨¡å—å¯¼å…¥
# --------------------------
# æ·»åŠ ä¸Šçº§ç›®å½•åˆ°æ¨¡å—æœç´¢è·¯å¾„ï¼ˆä¿è¯èƒ½å¯¼å…¥ lexer å’Œ temp_parserï¼‰
sys.path.append(os.path.dirname(__file__) + "/..")

try:
    from lexer import tokenize
    from generated_compiler.temp_parser import parse
except ImportError as e:
    raise ImportError("è¯·å…ˆè¿è¡Œ generator_main.py ç”Ÿæˆç›®æ ‡ç¼–è¯‘å™¨ï¼") from e

# --------------------------
# æ ¸å¿ƒè¾…åŠ©å‡½æ•°ï¼šæå–è¯­æ³•ç»“æ„ä¿¡æ¯ï¼ˆæ¨¡æ‹ŸASTæ‘˜è¦ï¼Œå®é™…å¯ä»parserè¿”å›å€¼è·å–ï¼‰
# --------------------------
def extract_syntax_structures(tokens):
    """
    ä»Tokenåˆ—è¡¨æå–å…³é”®è¯­æ³•ç»“æ„ä¿¡æ¯
    ï¼ˆå®é™…é¡¹ç›®ä¸­å¯æ›¿æ¢ä¸ºparserè¿”å›çš„ASTè§£æç»“æœï¼‰
    """
    structures = []
    current_func = None  # å½“å‰å¤„ç†çš„å‡½æ•°
    line_num = 1         # è¡Œå·è¿½è¸ª
    token_idx = 0        # Tokenç´¢å¼•

    while token_idx < len(tokens):
        token = tokens[token_idx]
        # è¿½è¸ªè¡Œå·ï¼ˆåŸºäºæ¢è¡Œç¬¦ï¼‰
        if token.value == "\n":
            line_num += 1
            token_idx += 1
            continue

        # 1. è¯†åˆ«å‡½æ•°å®šä¹‰ï¼ˆint/void + æ ‡è¯†ç¬¦ + (ï¼‰
        if token.type in ["INT", "VOID"] and token_idx + 2 < len(tokens):
            next1 = tokens[token_idx + 1]
            next2 = tokens[token_idx + 2]
            if next1.type == "IDENTIFIER" and next2.type == "LPAREN":
                func_type = token.value
                func_name = next1.value
                current_func = func_name
                # æå–å‚æ•°åˆ—è¡¨ï¼ˆç®€åŒ–ç‰ˆï¼‰
                params = []
                param_idx = token_idx + 3
                while param_idx < len(tokens) and tokens[param_idx].type != "RPAREN":
                    if tokens[param_idx].type in ["INT", "VOID"] and param_idx + 1 < len(tokens):
                        param_type = tokens[param_idx].value
                        param_name = tokens[param_idx + 1].value
                        params.append({"name": param_name, "type": param_type})
                        param_idx += 2
                    param_idx += 1
                # æ·»åŠ å‡½æ•°å®šä¹‰ç»“æ„
                structures.append(SyntaxStructure(
                    type="å‡½æ•°å®šä¹‰",
                    name=func_name,
                    scope="å…¨å±€",
                    line=line_num,
                    attrs={"è¿”å›å€¼ç±»å‹": func_type, "å‚æ•°åˆ—è¡¨": params}
                ))
                token_idx += 3
                continue

        # 2. è¯†åˆ«å˜é‡å£°æ˜ï¼ˆint/void + æ ‡è¯†ç¬¦ + ;ï¼‰
        if token.type in ["INT", "VOID"] and token_idx + 2 < len(tokens):
            next1 = tokens[token_idx + 1]
            next2 = tokens[token_idx + 2]
            if next1.type == "IDENTIFIER" and next2.type == "SEMI":
                var_name = next1.value
                var_type = token.value
                structures.append(SyntaxStructure(
                    type="å˜é‡å£°æ˜",
                    name=var_name,
                    scope=f"å‡½æ•°{current_func}å†…" if current_func else "å…¨å±€",
                    line=line_num,
                    attrs={"å˜é‡ç±»å‹": var_type}
                ))
                token_idx += 3
                continue

        # 3. è¯†åˆ«èµ‹å€¼è¯­å¥ï¼ˆset + æ ‡è¯†ç¬¦ + =ï¼‰
        if token.type == "SET" and token_idx + 2 < len(tokens):
            next1 = tokens[token_idx + 1]
            next2 = tokens[token_idx + 2]
            if next1.type == "IDENTIFIER" and next2.type == "ASSIGN":
                target_var = next1.value
                # æå–è¡¨è¾¾å¼ï¼ˆç®€åŒ–ç‰ˆï¼‰
                expr_tokens = []
                expr_idx = token_idx + 3
                while expr_idx < len(tokens) and tokens[expr_idx].type != "SEMI":
                    expr_tokens.append(f"{tokens[expr_idx].value}")
                    expr_idx += 1
                expr = " ".join(expr_tokens)
                structures.append(SyntaxStructure(
                    type="èµ‹å€¼è¯­å¥",
                    name=target_var,
                    scope=f"å‡½æ•°{current_func}å†…" if current_func else "å…¨å±€",
                    line=line_num,
                    attrs={"è¡¨è¾¾å¼": expr}
                ))
                token_idx += 3
                continue

        # 4. è¯†åˆ«æ§åˆ¶æµè¯­å¥ï¼ˆif/whileï¼‰
        if token.type in ["IF", "WHILE"] and token_idx + 1 < len(tokens) and tokens[token_idx + 1].type == "LPAREN":
            stmt_type = "ifæ¡ä»¶è¯­å¥" if token.type == "IF" else "whileå¾ªç¯è¯­å¥"
            # æå–æ¡ä»¶è¡¨è¾¾å¼
            cond_tokens = []
            cond_idx = token_idx + 2
            while cond_idx < len(tokens) and tokens[cond_idx].type != "RPAREN":
                cond_tokens.append(tokens[cond_idx].value)
                cond_idx += 1
            cond = " ".join(cond_tokens)
            structures.append(SyntaxStructure(
                type=stmt_type,
                name="",
                scope=f"å‡½æ•°{current_func}å†…" if current_func else "å…¨å±€",
                line=line_num,
                attrs={"æ¡ä»¶è¡¨è¾¾å¼": cond}
            ))
            token_idx += 2
            continue

        # 5. è¯†åˆ«returnè¯­å¥
        if token.type == "RETURN":
            # æå–è¿”å›å€¼
            return_val = ""
            ret_idx = token_idx + 1
            while ret_idx < len(tokens) and tokens[ret_idx].type != "SEMI":
                return_val += tokens[ret_idx].value + " "
                ret_idx += 1
            return_val = return_val.strip()
            structures.append(SyntaxStructure(
                type="returnè¯­å¥",
                name="",
                scope=f"å‡½æ•°{current_func}å†…" if current_func else "å…¨å±€",
                line=line_num,
                attrs={"è¿”å›å€¼": return_val if return_val else "ç©º"}
            ))
            token_idx += 1
            continue

        token_idx += 1

    return structures

# --------------------------
# ç”ŸæˆASTæ‘˜è¦ï¼ˆé¢å‘ä¸­é—´ä»£ç ç”Ÿæˆï¼‰
# --------------------------
def generate_ast_summary(structures):
    """ç”Ÿæˆç®€åŒ–çš„ASTæ‘˜è¦å­—ç¬¦ä¸²"""
    ast_lines = ["Program"]
    func_structures = [s for s in structures if s.type == "å‡½æ•°å®šä¹‰"]
    for func in func_structures:
        ast_lines.append(f"â””â”€â”€ FunctionDef(name={func.name}, return_type={func.attrs['è¿”å›å€¼ç±»å‹']})")
        ast_lines.append(f"    â”œâ”€â”€ ParamList: {func.attrs['å‚æ•°åˆ—è¡¨']}")
        ast_lines.append(f"    â””â”€â”€ StmtList")
        # æå–è¯¥å‡½æ•°å†…çš„è¯­å¥
        func_stmts = [s for s in structures if s.scope == f"å‡½æ•°{func.name}å†…" and s.type != "å‡½æ•°å®šä¹‰"]
        for stmt in func_stmts:
            if stmt.type == "å˜é‡å£°æ˜":
                ast_lines.append(f"        â”œâ”€â”€ VarDecl(name={stmt.name}, type={stmt.attrs['å˜é‡ç±»å‹']})")
            elif stmt.type == "èµ‹å€¼è¯­å¥":
                ast_lines.append(f"        â”œâ”€â”€ AssignStmt(target={stmt.name}, expr={stmt.attrs['è¡¨è¾¾å¼']})")
            elif stmt.type == "ifæ¡ä»¶è¯­å¥":
                ast_lines.append(f"        â”œâ”€â”€ IfStmt(cond={stmt.attrs['æ¡ä»¶è¡¨è¾¾å¼']})")
            elif stmt.type == "whileå¾ªç¯è¯­å¥":
                ast_lines.append(f"        â”œâ”€â”€ WhileStmt(cond={stmt.attrs['æ¡ä»¶è¡¨è¾¾å¼']})")
            elif stmt.type == "returnè¯­å¥":
                ast_lines.append(f"        â”œâ”€â”€ ReturnStmt({stmt.attrs['è¿”å›å€¼']})")
    return "\n".join(ast_lines)

# --------------------------
# ä¸»æµ‹è¯•é€»è¾‘
# --------------------------
if __name__ == "__main__":
    # ä¿®æ”¹åçš„æµ‹è¯•ä»£ç ï¼Œç¬¦åˆç°æœ‰ LL(1) æ–‡æ³•
    test_code = """
int foo(int x) {
    int y;
    set y = x * 5 + 3;  
    if (y > 10) {
        return y;
    }
    while (y < 20) {
        set y = y + 1;  
    }
    return 0;
}

void bar() {
    return;
}
    """

    # --------------------------
    # 1. è¯æ³•åˆ†æ
    # --------------------------
    print("=" * 50)
    print("1. è¯æ³•åˆ†æç»“æœï¼ˆå¸¦æ ¸å¿ƒä¸Šä¸‹æ–‡ï¼‰")
    print("=" * 50)
    tokens = tokenize(test_code)
    for idx, t in enumerate(tokens):
        # è¿‡æ»¤çº¯ç©ºç™½ç¬¦ï¼ˆä¿ç•™æœ‰æ„ä¹‰Tokenï¼‰
        if t.type not in ["WHITESPACE", "NEWLINE"] or t.value.strip() != "":
            print(f"Token[{idx}] | type={t.type:<12} | value={t.value:<8}")

    # --------------------------
    # 2. è¯­æ³•åˆ†æ
    # --------------------------
    print("\n" + "=" * 50)
    print("2. LL(1) è¯­æ³•åˆ†æè¿‡ç¨‹")
    print("=" * 50)
    # å°† Token å¯¹è±¡è½¬æ¢ä¸º LL(1) parser å¯è¯†åˆ«çš„ç±»å‹å­—ç¬¦ä¸²åºåˆ—
    token_types = [t.type for t in tokens if t.type not in ["WHITESPACE", "NEWLINE"]]
    token_types.append('$')  # æ·»åŠ  LL(1) parser ç»“æŸç¬¦

    # è°ƒç”¨ LL(1) parser
    success = parse(token_types, verbose=True)

    # --------------------------
    # 3. è¯­æ³•åˆ†æç»“æœæ€»ç»“ï¼ˆé¢å‘ä¸­é—´ä»£ç ç”Ÿæˆï¼‰
    # --------------------------
    print("\n" + "=" * 50)
    print("3. è¯­æ³•ç¼–è¯‘å™¨è¿è¡Œæ€»ç»“ï¼ˆä¾›ä¸­é—´ä»£ç ç”Ÿæˆå‚è€ƒï¼‰")
    print("=" * 50)
    if success:
        print("âœ… è¯­æ³•åˆ†æçŠ¶æ€ï¼šé€šè¿‡ï¼ˆæ— è¯­æ³•é”™è¯¯ï¼‰")
        
        # æå–è¯­æ³•ç»“æ„ä¿¡æ¯
        syntax_structures = extract_syntax_structures(tokens)
        
        # 3.1 æ ¸å¿ƒè¯­æ³•ç»“æ„æ¸…å•
        print("\nğŸ“‹ è¯†åˆ«åˆ°çš„æ ¸å¿ƒè¯­æ³•ç»“æ„ï¼š")
        for idx, struct in enumerate(syntax_structures, 1):
            print(f"   {idx}. {struct.type}")
            print(f"      - åç§°/ä½œç”¨åŸŸï¼š{struct.name or 'æ— '} | {struct.scope}")
            # print(f"      - è¡Œå·ï¼š{struct.line}")
            print(f"      - å…³é”®å±æ€§ï¼š{struct.attrs}")
        
        # 3.2 ASTæ‘˜è¦ï¼ˆç®€åŒ–ç‰ˆï¼‰
        print("\nğŸŒ³ ASTç»“æ„æ‘˜è¦ï¼š")
        ast_summary = generate_ast_summary(syntax_structures)
        print(f"   {ast_summary}")
        
        # 3.3 ä¸­é—´ä»£ç ç”Ÿæˆå»ºè®®
        print("\nğŸ’¡ ä¸­é—´ä»£ç ç”Ÿæˆå»ºè®®ï¼š")
        print("   - å‡½æ•°fooï¼šå±€éƒ¨å˜é‡yåˆ†é…æ ˆç©ºé—´ï¼Œè¡¨è¾¾å¼x*5+3éœ€æŒ‰ä¼˜å…ˆçº§ç”Ÿæˆï¼ˆt1=x*5; t2=t1+3; y=t2ï¼‰")
        print("   - å‡½æ•°barï¼šæ— å‚æ•°æ— è¿”å›å€¼ï¼Œreturnè¯­å¥ç”Ÿæˆç©ºè¿”å›æŒ‡ä»¤")
        print("   - æ§åˆ¶æµï¼šif/whileæ¡ä»¶éœ€ç”Ÿæˆè·³è½¬æŒ‡ä»¤ï¼Œå¾ªç¯ä½“éœ€å¤„ç†ç»ˆæ­¢æ¡ä»¶")
        
    else:
        print("âŒ è¯­æ³•åˆ†æçŠ¶æ€ï¼šå¤±è´¥ï¼ˆæ£€æµ‹åˆ°è¯­æ³•é”™è¯¯ï¼‰")
        print("\nâ“ é”™è¯¯æ’æŸ¥å»ºè®®ï¼ˆä¾›ä¸­é—´ä»£ç ç”Ÿæˆå‚è€ƒï¼‰ï¼š")
        print("   - è¯·å…ˆä¿®å¤è¯­æ³•é”™è¯¯ï¼ˆå¦‚ç¼ºå°‘åˆ†å·ã€æ‹¬å·ä¸åŒ¹é…ã€å…³é”®å­—æ‹¼å†™é”™è¯¯ï¼‰")
        print("   - é”™è¯¯ä½ç½®å¯ç»“åˆä¸Šæ–¹ã€è¯­æ³•åˆ†æè¿‡ç¨‹ã€çš„STACK TOP/LOOKAHEADä¸åŒ¹é…å¤„å®šä½")
        print("   - ä¿®å¤åé‡æ–°è¿è¡Œæµ‹è¯•ï¼Œç¡®è®¤è¯­æ³•é€šè¿‡åå†è¿›è¡Œä¸­é—´ä»£ç ç”Ÿæˆ")

    print("\n" + "=" * 50)
    print("4. æµ‹è¯•å®Œæˆ")
    print("=" * 50)